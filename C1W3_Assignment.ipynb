{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQjHqsmTAVLU"
   },
   "source": [
    "# Week 3: Improve MNIST with Convolutions\n",
    "\n",
    "In the videos you looked at how you would improve Fashion MNIST using Convolutions. For this exercise see if you can improve MNIST to 99.5% accuracy or more by adding only a single convolutional layer and a single MaxPooling 2D layer to the model from the  assignment of the previous week. \n",
    "\n",
    "You should stop training once the accuracy goes above this amount. It should happen in less than 10 epochs, so it's ok to hard code the number of epochs for training, but your training must end once it hits the above metric. If it doesn't, then you'll need to redesign your callback.\n",
    "\n",
    "When 99.5% accuracy has been hit, you should print out the string \"Reached 99.5% accuracy so cancelling training!\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZpztRwBouwYp"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by loading the data. A couple of things to notice:\n",
    "\n",
    "- The file `mnist.npz` is already included in the current workspace under the `data` directory. By default the `load_data` from Keras accepts a path relative to `~/.keras/datasets` but in this case it is stored somewhere else, as a result of this, you need to specify the full path.\n",
    "\n",
    "- `load_data` returns the train and test sets in the form of the tuples `(x_train, y_train), (x_test, y_test)` but in this exercise you will be needing only the train set so you can ignore the second tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "# Get current working directory\n",
    "current_dir = os.getcwd() \n",
    "\n",
    "# Append data/mnist.npz to the previous path to get the full path\n",
    "data_path = os.path.join(current_dir, \"data/mnist.npz\") \n",
    "\n",
    "# Get only training set\n",
    "(training_images, training_labels), _ = tf.keras.datasets.mnist.load_data(path=data_path) \n",
    "\n",
    "#check the images shapes\n",
    "print(np.shape(training_images))\n",
    "print(np.shape(training_images)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important step when dealing with image data is to preprocess the data. During the preprocess step you can apply transformations to the dataset that will be fed into your convolutional neural network.\n",
    "\n",
    "Here you will apply two transformations to the data:\n",
    "- Reshape the data so that it has an extra dimension. The reason for this \n",
    "is that commonly you will use 3-dimensional arrays (without counting the batch dimension) to represent image data. The third dimension represents the color using RGB values. This data might be in black and white format so the third dimension doesn't really add any additional information for the classification process but it is a good practice regardless.\n",
    "\n",
    "\n",
    "- Normalize the pixel values so that these are values between 0 and 1. You can achieve this by dividing every value in the array by the maximum.\n",
    "\n",
    "Remember that these tensors are of type `numpy.ndarray` so you can use functions like [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) or [divide](https://numpy.org/doc/stable/reference/generated/numpy.divide.html) to complete the `reshape_and_normalize` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: reshape_and_normalize\n",
    "\n",
    "def reshape_and_normalize(images):\n",
    "    \n",
    "    #get the first dimension of 'images' (total of image files):\n",
    "    FIRST_DIM = np.shape(images)[0]\n",
    "    \n",
    "    #2nd DIM will be the total of pixels in axis X:\n",
    "    SECOND_DIM = np.shape(images)[1]\n",
    "    \n",
    "    #3rd DIM will be the total of pixels in axis Y:\n",
    "    THIRD_DIM = np.shape(images)[2]\n",
    "    \n",
    "    #the last dimension of the reshaped image will be 1, since we are dealing of gray scale (1 byte per pixel):\n",
    "    LAST_DIM = 1\n",
    "    \n",
    "    # Reshape the images to add an extra dimension\n",
    "    #The extra dimension represents the new image format.\n",
    "    images = np.reshape(images, (FIRST_DIM, SECOND_DIM, THIRD_DIM, LAST_DIM))\n",
    "    #This reshape function can be applied to images of different shapes\n",
    "    \n",
    "    # Normalize pixel values\n",
    "    #apply min-max normalization to make the intensities from 0 to 1.\n",
    "    images = images/ 255.0\n",
    "    #Since in RGB intensities go from zero to 255, this normalization is equivalent to simply dividing by the\n",
    "    #max possible value\n",
    "    #We add the .0 at the end of the number to guarantee a float64 division.\n",
    "    \n",
    "    return images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function with the next cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value after normalization: 1.0\n",
      "\n",
      "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
      "\n",
      "Shape of one image after reshaping: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# Reload the images in case you run this cell multiple times\n",
    "(training_images, _), _ = tf.keras.datasets.mnist.load_data(path=data_path) \n",
    "\n",
    "# Apply your function\n",
    "training_images = reshape_and_normalize(training_images)\n",
    "\n",
    "print(f\"Maximum pixel value after normalization: {np.max(training_images)}\\n\")\n",
    "print(f\"Shape of training set after reshaping: {training_images.shape}\\n\")\n",
    "print(f\"Shape of one image after reshaping: {training_images[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "```\n",
    "Maximum pixel value after normalization: 1.0\n",
    "\n",
    "Shape of training set after reshaping: (60000, 28, 28, 1)\n",
    "\n",
    "Shape of one image after reshaping: (28, 28, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now complete the callback that will ensure that training will stop after an accuracy of 99.5% is reached:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED CLASS: myCallback\n",
    "### START CODE HERE\n",
    "\n",
    "# Remember to inherit from the correct class\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    #This class is actually created from the Tensorflow's Callback classes\n",
    "    #It makes it possible to use the objects created from this class in Keras neural networks.\n",
    "    \n",
    "        # Define the correct function signature for on_epoch_end\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            \n",
    "            # Halts the training after reaching 99.5 percent accuracy\n",
    "            #Args:\n",
    "              #epoch (integer) - index of epoch (required but unused in the function definition below)\n",
    "              #logs (dict) - metric results from the training epoch\n",
    "            \n",
    "            if ((logs.get('accuracy') is not None) and (logs.get('accuracy') > 0.995)):\n",
    "                print(\"\\nReached 99.5% accuracy so cancelling training!\") \n",
    "                \n",
    "                # Stop training once the above condition is met\n",
    "                self.model.stop_training = True\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, complete the `convolutional_model` function below. This function should return your convolutional neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: convolutional_model\n",
    "def convolutional_model():\n",
    "    ### START CODE HERE\n",
    "    \n",
    "    #Get the shape of the training_images\n",
    "    #In Keras, all images should have same dimensions. Then, we can pick the size of the first image\n",
    "    \n",
    "    #If images are of a general format, you could use the following code line, passing 'training_images' as argument of the function:\n",
    "    #INPUT_SHAPE = training_images[0].shape\n",
    "    #It is expected that INPUT_SHAPE = (28, 28, 1)\n",
    "    \n",
    "    #Since this exercise demands that there is no argument on the function, let's manually define the shape:\n",
    "    INPUT_SHAPE = (28, 28, 1)\n",
    "    print(f\"INPUT_SHAPE = {INPUT_SHAPE}\")\n",
    "    #Use f\"INPUT_STRING {}\" to print a numeric expression, an array, etc. \n",
    "    #The expression, array, value, etc that is indicated within the brackets will be print together with the string.\n",
    "    \n",
    "    # Define the model, it should have 5 layers:\n",
    "    # - A Conv2D layer with 32 filters, a kernel_size of 3x3, ReLU activation function\n",
    "    #    and an input shape that matches that of every image in the training set\n",
    "    # - A MaxPooling2D layer with a pool_size of 2x2\n",
    "    # - A Flatten layer with no arguments\n",
    "    # - A Dense layer with 128 units and ReLU activation function\n",
    "    # - A Dense layer with 10 units and softmax activation function\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        \n",
    "        # Add convolutions and max pooling\n",
    "        #Add a convolution layer with 32 filters (32 convolutions), kernel_size = (3,3), activation = 'relu':\n",
    "        tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = INPUT_SHAPE),\n",
    "        #Since INPUT_SHAPE was calculated from the shape of the image itself, there is no risk of shape mismatching.\n",
    "        #An expected shape is input_shape = (28, 28, 1)\n",
    "        \n",
    "        #First argument of Conv2D: 32 = number of convolutions; use powers of 2: 32, 64, etc;\n",
    "        #These powers usually start from 2^5 = 32.\n",
    "        #Second argument of Conv2D: (3, 3): dimensions of the convolution filter. It takes a 3x3 matrix (pixel and 8 surrounding pixels)\n",
    "        #The value of this central pixel after filtering will be the sum of the products between the intensity of a pixel and the number\n",
    "        #on the correspondent position of the Kernel (position of the filter).\n",
    "        #input_shape: dimensions of the images. (28, 28) is the dimension of the 28 x 28 pixels, input_shape[2] = 1 is color depth.\n",
    "        #Since we are using gray scale, we need only a single byte, so this dimension is 1.\n",
    "        #In gray scale, image depth = 1;\n",
    "        #For a color image (RGB system), image depth = 3 due to use of the 3 channels (Red, Blue, and Green).\n",
    "        \n",
    "        #Add a MaxPooling2D layer with pool_size of 2x2\n",
    "        tf.keras.layers.MaxPooling2D(2, 2),\n",
    "        #Argument of MaxPooling2D: (2, 2) - the image is divided into several (2 x 2) pixels matrices. For each matrix, only the highest\n",
    "        #(maximum) pixel intensity is selected (maximum value is kept, whereas the others are removed). After that, the selected values\n",
    "        #are merged to form a new matrix. The length of the X axis of the new matrix is equal to the input X length divided by 2.\n",
    "        #Also, the Y length is the input Y length divided by 2.\n",
    "        \n",
    "        #Add a Flatten layer with no arguments, to convert the images to a 1-D array that will be processed by the Dense\n",
    "        #neural networks:\n",
    "        tf.keras.layers.Flatten(),\n",
    "\n",
    "        #We do not have to define the input shape of the Flatten. It will be simply the input_shape of the images being fed.\n",
    "        #Since the images passed through convolutions and pooling, each dimension was reduced in 2 units by each (3, 3) convolution \n",
    "        #(removal of the edges, where the pixels do not have 8 neighbors for the kernel filter to be applied); and were divided by 2 \n",
    "        #by each of the (2, 2) MaxPoolings. If this division does not result in an integer, the dimension is rounded down to the \n",
    "        #lower integer that is closer to the division. e.g., if the division results in 5.5, the new dimension will be 5.\n",
    "        \n",
    "        #Add a Dense layer with 128 neurons (128 units) activated through ReLU:\n",
    "        tf.keras.layers.Dense(128, activation='relu'),\n",
    "        \n",
    "        #Add a final Dense layer activated through 'softmax'. Since we want Keras to classify the images among 10 different\n",
    "        #classes, this layer should have 10 neurons:\n",
    "        tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='sparse_categorical_crossentropy', \n",
    "                  metrics=['accuracy']) \n",
    "    \n",
    "    #'sparse_categorical_crossentropy' is a loss metric adequate for classification problems, not for regression ones.\n",
    "    #For regressions, we use 'mean_squared_error', for instance.\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save your untrained model\n",
    "model = convolutional_model()\n",
    "\n",
    "# Instantiate the callback class\n",
    "callbacks = myCallback()\n",
    "\n",
    "# Train your model (this can take up to 5 minutes)\n",
    "history = model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see the message that you defined in your callback printed out after less than 10 epochs it means your callback worked as expected. You can also double check by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Your model was trained for {len(history.epoch)} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on finishing this week's assignment!**\n",
    "\n",
    "You have successfully implemented a CNN to assist you in the image classification task. Nice job!\n",
    "\n",
    "**Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
